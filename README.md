
# ğŸ¬ Multimodal Video Highlight Generator

This project provides a multimodal video highlight generation tool based on audio and visual analysis. It uses OpenAI GPT models and Whisper transcription to identify and extract the most meaningful segments from full-length videos and automatically generate a concise highlight clip.

##  Author: Page(Peizhi) Zhu, Beichen Yu, Lynda Li

## ğŸ“¦ Project Structure

| File | Description |
|------|-------------|
| `gui_app.py` | Main interactive interface built with Gradio |
| `highlight_editor.py` | Core logic: scoring, filtering, segment merging, clip generation |
| `audio_analysis.py` | Whisper-based transcription and GPT-based audio semantic/emotional analysis |
| `visual_analysis.py` | Frame extraction and GPT-based visual content + color theme analysis |
| `test.py` | Sample test entry to run the analysis pipeline |
| `util.py` | Utility functions for image processing, merging, JSON extraction, etc. |

## ğŸš€ Key Features

- ğŸ§ **Audio Analysis**: Transcription with timestamps, GPT-powered emotional and thematic analysis
- ğŸ–¼ï¸ **Visual Analysis**: Keyframe extraction, color theme classification, visual content description
- ğŸ¤– **GPT Integration**: Uses `gpt-4o-mini` or `gpt-3.5-turbo` for all intelligent interpretation tasks
- ğŸ“Š **Multidimensional Filtering**: Filter by emotion, theme, genre, dialogue type, and more
- âœ‚ï¸ **Automatic Highlighting**: Extracts and merges top-scoring segments into a final highlight video
- ğŸ’» **User-Friendly GUI**: Full workflow managed via Gradio-based interface

## ğŸ§  Highlights

- âœ… **Keyword-Optional**: If no keyword is entered, the system will fall back to confidence-based scoring
- ğŸ” **Multimodal Matching**: Combines GPT relevance score and embedding-based semantic similarity
- ğŸ” **Segment Merging**: Merges nearby clips to form coherent highlights
- â±ï¸ **Duration Limit**: Total output duration can be capped (e.g., 60 seconds)
- ğŸ›¡ï¸ **Fallback Logic**: If filters are too strict, system auto-relaxes constraints to ensure results

## ğŸ›  Installation

```bash
pip install -r requirements.txt
```

### Key dependencies:
- `gradio`
- `openai`
- `moviepy`
- `faster-whisper`
- `sentence-transformers`
- `opencv-python`
- `scenedetect`

## ğŸ’» How to Launch the GUI

```bash
python gui_app.py
```

Visit [http://localhost:7860](http://localhost:7860) in your browser.

## ğŸ“‚ Workflow (GUI)

1. Select or upload a video
2. Optionally enter a keyword (e.g., â€œdangerâ€)
3. Click **Start Analysis** to perform both audio and visual analysis
4. View summaries and filter statistics
5. Select desired filters (theme, mood, genre, emotion, dialogue type)
6. Click **Generate Highlight** to produce the final video

## ğŸ“ Output Directory Structure

```
video_outputs/
â””â”€â”€ <video_name>/
    â”œâ”€â”€ audio_results/
    â”‚   â””â”€â”€ audio_analysis_results.json
    â”œâ”€â”€ visual_results/
    â”‚   â””â”€â”€ visual_analysis_result.json
    â”œâ”€â”€ highlight.mp4
    â””â”€â”€ highlight_metadata.json
```

## ğŸ”§ CLI Mode (for batch testing)

```bash
python highlight_editor.py
```

Edit the `__main__` section in `highlight_editor.py` to set `video_path` and `output_path`.

## ğŸ“© Contact

For questions, collaboration, or issues, please reach out COMP5425 Project Group9: beyu0824 pzhu0521 chdu0298 yuli4954
